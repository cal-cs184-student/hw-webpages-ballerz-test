<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Krishna Mani, Brandon Huang</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-ballerz-test/">https://cal-cs184-student.github.io/hw-webpages-ballerz-test/5</a>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-ballerz2">https://github.com/cal-cs184-student/sp25-hw3-ballerz2</a>
		
		<!-- <figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure> -->

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		We implemented ray generation and scene intersection algorithms, the BVH construction algorithm, both versions of the direct lighting function (with uniform hemisphere sampling and with importance sampling lights), global illumination (the indirect lighting function), and adaptive sampling. We then tested these techniques on real images.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>

		<h3>Ray Generation and Primitive Intersection Parts of the Rendering Pipeline</h3>

		In ray generation, my implementation takes in normalized coordinates in the image space and maps them to the sensor, or coordinates in the camera space. I implemented this coordinate transformation by using the formulas sensorX = (2*x - 1) * tan(hFov/2) and sensorY = (2*y - 1) * tan(vFov/2). sensorZ is set to -1 because in camera space, the ray points forward in the negative z-direction. This ray, which is in the camera space, is then transformed into a ray in world space using the camera-to-world rotation matrix (c2w). After normalizing this ray, I initialize a ray with its origin as the camera’s position, and its direction as the normalized world space ray. I also set this ray’s min and max bounds to nclip and fclip, the near and far clipping planes.
		For the primitive intersection part, given the inputted pixel, multiple samples are generated based on the number of samples (ns_aa). For each sample, a ray is generated from the camera through the sample point. Then, my implementation calls est_radiance_global_illumination() on each ray to calculate the ray’s radiance, and all of these rays’ radiances are averaged. The pixel’s radiance is then updated in sampleBuffer.

		<h4>Triangle Intersection Algorithm</h4>

		For my implementation, I decided to use the Möller-Trumbore intersection algorithm, where I do multiple checks to see if there is a valid intersection, including checking if the ray is parallel to the triangle and checking if the intersection point is outside of the triangle. First, I calculated two edges of the triangle (edge1, edge2) using its vertices, then the cross product between the ray’s direction and edge2 (h). The determinant is calculated as the dot product between edge1 and this cross product h. If the determinant is close to 0, it means the ray is parallel to the triangle, so there is no intersection and I return false. Otherwise, I continued by computing the barycentric coordinates (u,v) to see if the intersection is inside the triangle. I first calculated the inverse of the determinant (f) and the difference between the ray’s origin and the first point (s). If u = f*dot(s,h) is not within [0,1], it means the intersection is outside of the triangle and I return false. Otherwise, I continued by calculating q, the cross product between s and edge1. If v = f*dot(ray’s direction, q) is not within [0,1], or if u+v is greater than 1, the point is outside the triangle and I return false. Otherwise, I do one final check. I calculate t = f*dot(edge2,q). If t is not within [min_t, max_t], the intersection is invalid so I return false. If t is within this range, it means we have found a valid intersection, so I update the ray’s max_t to this intersection point. My implementation then calculates the interpolated surface normal using the barycentric coordinates, as (1-u-v)*n1 + u*n2 + v*n3, and stores all of the intersection information in the Intersection object.
		
		<p>Images with Normal Shading</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image1.png" width="400px"/>
				  <figcaption>CBempty.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image2.png" width="400px"/>
				  <figcaption>CBspheres.png</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>

		<h3>BVH Construction Algorithm</h3>

		For my BVH construction algorithm, I first compute the bounding box by iterating through each primitive and expand the bounding box to include each primitive’s bounding box. I create a new BVH node with this computed bounding box and store the start and end iterators to reference the primitives. If the number of primitives is no more than max_leaf_size, the node we created is a leaf node and the current node is returned. Then, for picking the splitting point, my implementation finds the longest axis (either x, y, or z) to divide the primitives, and sorts the primitives based on the centroid of their bounding boxes in the chosen axis or direction. I find the middle point (between start and num_primitives) to divide the primitives into two halves, and recursively construct the left (start to mid) and right (mid to end) subtrees, before returning the node at the end.

		<p>Images with Normal Shading Rendered with BVH Acceleration</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image3.png" width="400px"/>
				  <figcaption>Cow.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image4.png" width="400px"/>
				  <figcaption>Maxplanck.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image5.png" width="400px"/>
				  <figcaption>CBlucy.png</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Rendering Time Comparison</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image6.png" width="400px"/>
				</td>
			  </tr>
			</table>
		</div>

		As shown by these data, the BVH accelerates rendering times by nearly a factor of 100 on complex geometries such as CBlucy.dae. For the smaller ones, the speedup is not as significant since the rendering is a smaller portion of the total time. This is because we don’t have to test every single primitive for intersection with every ray; the majority of the computation is saved since the tree structure enables us to find the correct primitives to test much more efficiently. Because of this, we can quickly render even geometries with hundreds of thousands of primitives.

		<h2>Part 3: Direct Illumination</h2>

		<h3>Implementation Descriptions</h3>

		<h4>Hemisphere sampling</h4>
		
		We generated num_samples uniform samples from the hemisphere, and used the analytic PDF for a hemisphere. For each sample, we cast a ray along this direction and check if it intersects the BVH. If it does, we record the emissivity of this point, adding to the total the intensity times the reflectance function, scaled by a cosine term according to Lambert’s rule and the PDF. All surfaces except lights (which have nonzero emissivity) will not contribute to the total. Then, this is averaged over the number of samples to complete the Monte Carlo estimate.

		<h4>Importance sampling</h4>
		
		Instead, we use num_samples for each light in the scene. Iterating over the lights, we cast num_samples rays toward the light using the light’s sampler. It returns the radiance and a PDF we can use. If this ray does not intersect the BVH, then it must be illuminating our point of interest. We add the same term as in hemispheric sampling, the reflectance function times the light’s intensity and a cosine term, scaled by the PDF. We then scale this total by the number of samples, to complete the Monte Carlo estimate and proceed to the next light.

		<p>Importance Sampling</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image7.png" width="400px"/>
				  <figcaption>spheres.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image8.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Hemisphere Sampling</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image9.png" width="400px"/>
				  <figcaption>spheres.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image10.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Now focusing on the CBbunny scene:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image11.png" width="400px"/>
				  <figcaption>I = 1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image12.png" width="400px"/>
				  <figcaption>I = 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image13.png" width="400px"/>
				  <figcaption>I = 16</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image14.png" width="400px"/>
				  <figcaption>I = 64</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		The soft shadows, underneath the bunny, are much less noisier with higher numbers of rays. This is because the shadows are in reality smooth, and approximating this accurately requires a relatively high number of samples. In the last image, there is nearly no noise in the shadow!

		<h3>Uniform Hemisphere Sampling vs. Lighting Sampling Results Comparison</h3>

		Understandably, the images rendered with importance sampling are less noisy. Because we have information about the distribution of the radiance in the scene (namely, the positions of the lights), we can dedicate our samples to those positions instead of uniformly from an intersection and “catch” more of the light. If you zoom into the hemisphere sampling images, there are “pockmarks” from directions that did not end in a light within m bounces (apparently a large number of them). This is absent from the importance sampling images, which are relatively noise-free since the majority contribution to a pixels’ brightness is the direct reflection of light off of it (if there is one), rather than the later ones, which are geometrically scaled by cosine terms. Overall, this just results in more accurate lighting–it is the same phenomenon that we saw with naive Monte Carlo estimators versus ones that incorporate a good prior. 

		<h2>Part 4: Global Illumination</h2>

		<h3>Implementation of Indirect Lighting Function</h3>
		
		In my implementation of the indirect lighting function, I first calculated the hit point as hit_p = r.o + r.d * isect.t and the outgoing direction as w2o * (-r.d), with w2o being the world-to-object matrix. Then, I used the one_bounce_radiance() function to compute the light coming from the first bounce. If the ray has reached the maximum depth, I return the current accumulated radiance. Otherwise, I continue by calling sample_f() to sample an incoming direction, w_in, from the BSDF, and compute BSDF value f and the pdf. Then, I implemented Russian Roulette to terminate rays, where I return the current accumulated radiance with a probability of 0.3 after a certain depth. In addition, I used the o2w matrix to transform the sample direction w_in back to world space. I also created a new ray, indirect_ray, but slightly offset by EPS_F to avoid self-intersection. If this new ray intersects with the scene, I recursively call at_least_one_bounce_radiance() to compute the indirect radiance (L_indirect), and calculate the contribution of the next bounce using the formula (L_indirect * BSDF value f * cos_theta / pdf). If isAccumBounces is true, we return the total radiance which is the sum of both the current bounce and next bounces, otherwise we only include the next bounces. Finally, if no intersection is found, we only return the direct radiance, which is the current bounce.

		<h3>Images Rendered with Global Illumination</h3>

		<p>Direct Lighting</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image15.png" width="400px"/>
				  <figcaption>spheres.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image16.png" width="400px"/>
				  <figcaption>dragon.dae</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image17.png" width="400px"/>
				  <figcaption>wall-e.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Indirect (Global) Lighting</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image18.png" width="400px"/>
				  <figcaption>spheres.png</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image19.png" width="400px"/>
				  <figcaption>dragon.dae</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image20.png" width="400px"/>
				  <figcaption>wall-e.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Scene with only direct illumination:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image21.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Scene with only global illumination:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image22.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Un-accumulated/accumulated bounces (isAccumBounces) for CBbunny.dae</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=0: These are the same since there's no bounces.</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image23.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image24.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=1: These are the same, except for the absence of the light directly from the top light</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image25.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image26.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=2: This is the reflection of light off either the bunny or one wall, off either the bunny or another wall, to the camera. It illuminates the bottom of the bunny, which is crucial to making the shadows realistic. The accumulated scene is miles better than the direct lit one.</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image27.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image28.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=3: This is the bounce after the previously explained one; it adds more detail in the shadows, which is particularly visible on the neck, behind the ears, and in the corners of the walls. It makes the shadows even more realistic, but the effect is less noticeable due to attenuation. The difference between the accumulated last one and this one is noticeable, but less so than between the previous two.</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image29.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image30.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=4: These have relatively low magnitude, and the accumulated scene is barely different.</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image31.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image32.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>m=5: I honestly could not find a difference. The delta is nearly black everywhere. Maybe the corners are a little brighter?</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image33.png" width="400px"/>
				  <figcaption>Un-accumulated</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image34.png" width="400px"/>
					<figcaption>Accumulated</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Scene with Russian Roulette Termination for CBbunny</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image35.png" width="400px"/>
				  <figcaption>m = 0</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image36.png" width="400px"/>
				  <figcaption>m = 1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image37.png" width="400px"/>
				  <figcaption>m = 2</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image38.png" width="400px"/>
				  <figcaption>m = 3</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image39.png" width="400px"/>
				  <figcaption>m = 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image40.png" width="400px"/>
				  <figcaption>m = 100</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Different Sampling Rates s with 4 Light Rays</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image41.png" width="400px"/>
				  <figcaption>s=1: Super noisy and artifacts with bright pixels in shadows.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image42.png" width="400px"/>
				  <figcaption>s=2: Not much better.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image43.png" width="400px"/>
				  <figcaption>s=4: Looking a little better, the shadows are starting to smooth out.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image44.png" width="400px"/>
				  <figcaption>s=8: A little better as well, focus on the shadow on the side of the closer sphere.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image45.png" width="400px"/>
				  <figcaption>s=16: Noise is still there, but slowly getting better.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image46.png" width="400px"/>
				  <figcaption>s=64: So much better looking than before! Barely visible noise, shadows are smooth and the ceiling is near uniform.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image47.png" width="400px"/>
				  <figcaption>s=1024: Looks perfect. No noticeable noise, although it takes like 100x as long to render.</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Part 5: Adaptive Sampling</h2>

		<h3>Explanation and Implementation of Adaptive Sampling</h3>

		<h4>Adaptive Sampling Explanation</h4>
		
		Adaptive sampling is a technique used in Monte Carlo path tracing to efficiently reduce noise by avoiding using a higher number of samples per pixel and instead concentrating the samples on “difficult” pixels, or pixels that have higher variance in their sampled values. Adaptive sampling also adjusts the number of samples per pixel based on how quickly the pixel’s estimated color converges.

		<h4>My Implementation</h4>
		
		In my implementation, I first initialized the total radiance of all samples for the given pixel, the sum of illuminance values, the sum of squared illuminance values, the number of samples collected so far for the given pixel, as well as the pixel’s location in the image. Then, while the number of samples collected so far is less than the maximum allowed samples, I use batches to collect multiple samples before checking for convergence, and trace batch_count rays through the pixel. I did this by using the get_sample() function to generate a sample within the pixel, creating a ray from the camera through the sample point, estimating the ray’s radiance using the est_radiance_global_illumination() function, and then accumulating the respective values for the total radiance, illuminance, and squared illuminance. After each batch, I increment the number of samples collected so far by batch_count. Then, I checked for convergence, which occurs if I = 1.96 * standard deviation of illuminance / sqrt(n) is less than or equal to maxTolerance * mean of illuminance, and I calculated the mean of standard deviation of illuminance using the formulas given in the task description. Finally, I divided by n to compute the average radiance, and stored this final computed color in sampleBuffer.

		<p>Sample Rate Image and Noise-Free Rendered Result</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<p>Scene 1 (CBspheres_lambertian): 2048 samples, rate/noise-free image</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image48.png" width="400px"/>
				  <figcaption>Sample rate image</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image49.png" width="400px"/>
					<figcaption>Noise-free image</figcaption>
				  </td>
			  </tr>
			</table>
			<p>Scene 2 (CBspheres_lambertian): 2048 samples, rate/noise-free image</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./hw3image50.png" width="400px"/>
				  <figcaption>Sample rate image</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="./hw3image51.png" width="400px"/>
					<figcaption>Noise-free image</figcaption>
				  </td>
			  </tr>
			</table>
		</div>

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<!-- <h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul> -->
		</div>
	</body>
</html>